{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d37198f5",
   "metadata": {},
   "source": [
    "## How to use Pandas more efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07589fe",
   "metadata": {},
   "source": [
    "The Pandas library is the tool that almost every data scientist will use every day. It is an awesome tool to explore and work with data. \n",
    "\n",
    "In this notebook, we would like to share a few good tricks such as using built-in functions and adopting vectorized operations that can speed up our pandas code and improve our productivity. The agenda would be: \n",
    "\n",
    "1. Selecting Rows and Columns using **.iloc[]** function is faster\n",
    "\n",
    "2. To iterate through all of rows of a dataframe, in terms of efficiency, vectorizing over pandas series > **.apply()** > **.iterrows()**\n",
    "\n",
    "3. Try to use more built-in functions such as **replace()** and **groupby()** functions. It could also speed up the process than our coding from scratch. \n",
    "\n",
    "In the following notebook, we will use the following dataset from Kaggle: \n",
    "\n",
    "\n",
    "[Crime in Chicago](https://www.kaggle.com/datasets/onlyrohit/crimes-in-chicago?resource=download) \n",
    "\n",
    "We took a random sample from it and the csv file is named **crimes_in_Chicago_subset.csv** which contains 36082 data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3b33ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### if we are using google colab, we need to run this cell to specify the path for data loading\n",
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "    # mount google drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    # specify the path of the folder containing \"file_name\" by changing the lecture index:\n",
    "    lecture_index = '01'\n",
    "    path_to_file = '/content/gdrive/My Drive/BT5153_2023/codes/lab_lecture{}/'.format(lecture_index) \n",
    "    print(path_to_file)\n",
    "    # change current path to the folder containing \"file_name\"\n",
    "    os.chdir(path_to_file)\n",
    "    !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2b9d0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_data = pd.read_csv('../data/crimes_in_Chicago_subset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cac3b580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36082, 22)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f00d04",
   "metadata": {},
   "source": [
    "### 1. Select rows and columns efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "092ff2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234 µs ± 94.8 µs per loop (mean ± std. dev. of 5 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r5 -n10 df_data.loc[range(0,600)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33dc540e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163 µs ± 83.4 µs per loop (mean ± std. dev. of 5 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r5 -n10 df_data.iloc[range(0,600)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4fcd9c",
   "metadata": {},
   "source": [
    "We can see iloc[] perform much faster than loc[] in selecting rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38c4e9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760 µs ± 95.7 µs per loop (mean ± std. dev. of 5 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "sub_cols = [\"ID\", \"Case Number\", \"Date\", \"Block\"]\n",
    "%timeit -r5 -n10 df_data.loc[:,sub_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18dbbf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "661 µs ± 114 µs per loop (mean ± std. dev. of 5 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "first3_cols = df_data.columns[:4]\n",
    "%timeit -r5 -n10 df_data.iloc[:,:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15d793d",
   "metadata": {},
   "source": [
    "We can see also that using the column indexing using .iloc[] is still faster than loc[]. So it is better to use .iloc[] for efficiency. However, sometimes, it would be more convenient to use .loc[] to select certain columns by name directly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c77262",
   "metadata": {},
   "source": [
    "### 2. Iterate through all rows of Dataframe\n",
    "\n",
    "It is quite common to create a new column based on one or more current columns using Pandas. Think about feature engineering. We can see the different ways for this operation using Pandas. The performances would be compared. \n",
    "\n",
    "For example, we would like to create a new column which is the sum of square of **X Coordinate** and **Y Coordinate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4cea744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "sum_square = lambda x, y: (x+y) ** 2\n",
    "print(sum_square(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ca89a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = df_data[['X Coordinate', 'Y Coordinate']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04fddd10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441 ms ± 1.45 ms per loop (mean ± std. dev. of 5 runs, 10 loops each)\n",
      "141 ms ± 3.14 ms per loop (mean ± std. dev. of 5 runs, 10 loops each)\n",
      "55.2 ms ± 626 µs per loop (mean ± std. dev. of 5 runs, 10 loops each)\n",
      "4.86 ms ± 108 µs per loop (mean ± std. dev. of 5 runs, 10 loops each)\n",
      "292 µs ± 55.1 µs per loop (mean ± std. dev. of 5 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r5 -n10 test_data.loc[:,'magic'] = [sum_square(value[0], value[1]) for _, value in test_data.iterrows()]\n",
    "%timeit -r5 -n10 test_data.loc[:,'magic'] = test_data.apply(lambda row: sum_square(row[0], row[1]), axis=1)\n",
    "%timeit -r5 -n10 test_data.loc[:,'magic']  = test_data.apply(lambda row: sum_square(row[0], row[1]), raw=True, axis=1)\n",
    "%timeit -r5 -n10 test_data.loc[:,'magic']  = np.vectorize(sum_square)(test_data.iloc[:,0], test_data.iloc[:,1])\n",
    "%timeit -r5 -n10 test_data.loc[:,'magic']  = np.power(test_data.iloc[:,0]+test_data.iloc[:,1], 2)\n",
    "#%timeit -r5 -n10 test_data.loc[:,'magic'] = [sum_square(value[0], value[1]) for _, value in test_data.iterrows()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82edf7e",
   "metadata": {},
   "source": [
    "The best solution is able to achieve **1700** time speed-up compared to the slowest one  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377ff592",
   "metadata": {},
   "source": [
    "#### Key Take-away:\n",
    "\n",
    "1. You should never use iterrows(). If you need to loop through a dataframe, try **itertuples**\n",
    "2. **raw=True** in the **apply** function is able to  bypass the overhead associated with the Pandas series object. Therefore, it can speed up the apply process.\n",
    "3. Make the function \"vetorized\" can yield the highest speed up. \n",
    "\n",
    "In most of cases, if the operation can be represented as linear algebra operations on matrices and scalar values, it can be vectorized using Numpy methods. \n",
    "\n",
    "For some operations/functions, it might not be easily vectorized. I prefer parallel processing because it requires the least amount of rewrite of your existing code. You simply have to add a few lines wrapper code to make it work. The example below illustrates how you can do this. For example, we can try **[Dask](https://www.dask.org/)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa827b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "test_data = df_data[['X Coordinate', 'Y Coordinate']].copy()\n",
    "ddf = dd.from_pandas(test_data, npartitions=4)\n",
    "sum_square = lambda row: (row[0]+row[1]) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13851cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.31 ms ± 175 µs per loop (mean ± std. dev. of 5 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r5 -n10 \n",
    "dask_series = ddf.apply(sum_square, axis=1, meta=('magic','float'))\n",
    "ddf['magic'] = dask_series\n",
    "df_new = ddf.compute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c189428b",
   "metadata": {},
   "source": [
    "The parallelization is able to have a 2.8 times speed up compared to the apply function in the mode of the serial processing. \n",
    "\n",
    "But for parallel processing, there is a difference between CPU bound (heavy scientific computing and data is in memory) vs I/O bound (making API request over internet). For cpu bound, we should use multiprocess while the task is I/O bound, the multithreading one would be better choice. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770d2359",
   "metadata": {},
   "source": [
    "### 3. Try to use build-in functions in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece8b07c",
   "metadata": {},
   "source": [
    "If we would like to replace values in Dataframe, we can call **.replace()** directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "28e98c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 8.89 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "3.32 ms ± 3.92 ms per loop (mean ± std. dev. of 5 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r5 -n10 df_data['Description'].loc[df_data.Description=='SIMPLE'] = 'simple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f5ec67aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18 ms ± 1.15 ms per loop (mean ± std. dev. of 5 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r5 -n10 df_data['Description'].replace({\"simple\": \"SIMPLE\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690341e1",
   "metadata": {},
   "source": [
    "We can see **.replace()** method is faster than the conventional coding method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "db0854cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Block</th>\n",
       "      <th>IUCR</th>\n",
       "      <th>Primary Type</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location Description</th>\n",
       "      <th>Arrest</th>\n",
       "      <th>Domestic</th>\n",
       "      <th>...</th>\n",
       "      <th>Ward</th>\n",
       "      <th>Community Area</th>\n",
       "      <th>FBI Code</th>\n",
       "      <th>X Coordinate</th>\n",
       "      <th>Y Coordinate</th>\n",
       "      <th>Year</th>\n",
       "      <th>Updated On</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10283110</td>\n",
       "      <td>HY471210</td>\n",
       "      <td>01/01/2011 12:00:00 AM</td>\n",
       "      <td>104XX S WENTWORTH AVE</td>\n",
       "      <td>1753</td>\n",
       "      <td>OFFENSE INVOLVING CHILDREN</td>\n",
       "      <td>SEX ASSLT OF CHILD BY FAM MBR</td>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>02</td>\n",
       "      <td>1176802.0</td>\n",
       "      <td>1835545.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>02/10/2018 03:50:01 PM</td>\n",
       "      <td>41.704075</td>\n",
       "      <td>-87.628194</td>\n",
       "      <td>(41.704075384, -87.628193565)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10295795</td>\n",
       "      <td>HY483570</td>\n",
       "      <td>01/01/2011 12:00:00 AM</td>\n",
       "      <td>061XX N FAIRFIELD AVE</td>\n",
       "      <td>1153</td>\n",
       "      <td>DECEPTIVE PRACTICE</td>\n",
       "      <td>FINANCIAL IDENTITY THEFT OVER $ 300</td>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1156892.0</td>\n",
       "      <td>1940584.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>02/09/2018 03:44:29 PM</td>\n",
       "      <td>41.992738</td>\n",
       "      <td>-87.698256</td>\n",
       "      <td>(41.992738481, -87.698256423)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10308026</td>\n",
       "      <td>HY496701</td>\n",
       "      <td>01/01/2011 12:00:00 AM</td>\n",
       "      <td>056XX W GOODMAN ST</td>\n",
       "      <td>1752</td>\n",
       "      <td>OFFENSE INVOLVING CHILDREN</td>\n",
       "      <td>AGG CRIM SEX ABUSE FAM MEMBER</td>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1137936.0</td>\n",
       "      <td>1932750.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>02/10/2018 03:50:01 PM</td>\n",
       "      <td>41.971606</td>\n",
       "      <td>-87.768174</td>\n",
       "      <td>(41.971605914, -87.768174187)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11616799</td>\n",
       "      <td>JC177993</td>\n",
       "      <td>01/01/2011 12:00:00 AM</td>\n",
       "      <td>046XX S LA CROSSE AVE</td>\n",
       "      <td>1154</td>\n",
       "      <td>DECEPTIVE PRACTICE</td>\n",
       "      <td>FINANCIAL IDENTITY THEFT $300 AND UNDER</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011</td>\n",
       "      <td>03/09/2019 04:05:42 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10902200</td>\n",
       "      <td>JA212148</td>\n",
       "      <td>01/01/2011 12:00:00 AM</td>\n",
       "      <td>0000X E 59TH ST</td>\n",
       "      <td>1154</td>\n",
       "      <td>DECEPTIVE PRACTICE</td>\n",
       "      <td>FINANCIAL IDENTITY THEFT $300 AND UNDER</td>\n",
       "      <td>APARTMENT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011</td>\n",
       "      <td>04/06/2017 03:56:56 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID Case Number                    Date                  Block  IUCR  \\\n",
       "0  10283110    HY471210  01/01/2011 12:00:00 AM  104XX S WENTWORTH AVE  1753   \n",
       "1  10295795    HY483570  01/01/2011 12:00:00 AM  061XX N FAIRFIELD AVE  1153   \n",
       "2  10308026    HY496701  01/01/2011 12:00:00 AM     056XX W GOODMAN ST  1752   \n",
       "3  11616799    JC177993  01/01/2011 12:00:00 AM  046XX S LA CROSSE AVE  1154   \n",
       "4  10902200    JA212148  01/01/2011 12:00:00 AM        0000X E 59TH ST  1154   \n",
       "\n",
       "                 Primary Type                              Description  \\\n",
       "0  OFFENSE INVOLVING CHILDREN            SEX ASSLT OF CHILD BY FAM MBR   \n",
       "1          DECEPTIVE PRACTICE      FINANCIAL IDENTITY THEFT OVER $ 300   \n",
       "2  OFFENSE INVOLVING CHILDREN            AGG CRIM SEX ABUSE FAM MEMBER   \n",
       "3          DECEPTIVE PRACTICE  FINANCIAL IDENTITY THEFT $300 AND UNDER   \n",
       "4          DECEPTIVE PRACTICE  FINANCIAL IDENTITY THEFT $300 AND UNDER   \n",
       "\n",
       "  Location Description  Arrest  Domestic  ...  Ward  Community Area  FBI Code  \\\n",
       "0            RESIDENCE   False      True  ...  34.0            49.0        02   \n",
       "1            RESIDENCE   False     False  ...  50.0             2.0        11   \n",
       "2            RESIDENCE   False      True  ...  45.0            11.0        20   \n",
       "3                OTHER   False     False  ...  22.0            56.0        11   \n",
       "4            APARTMENT   False     False  ...  20.0            40.0        11   \n",
       "\n",
       "   X Coordinate Y Coordinate  Year              Updated On   Latitude  \\\n",
       "0     1176802.0    1835545.0  2011  02/10/2018 03:50:01 PM  41.704075   \n",
       "1     1156892.0    1940584.0  2011  02/09/2018 03:44:29 PM  41.992738   \n",
       "2     1137936.0    1932750.0  2011  02/10/2018 03:50:01 PM  41.971606   \n",
       "3           NaN          NaN  2011  03/09/2019 04:05:42 PM        NaN   \n",
       "4           NaN          NaN  2011  04/06/2017 03:56:56 PM        NaN   \n",
       "\n",
       "   Longitude                       Location  \n",
       "0 -87.628194  (41.704075384, -87.628193565)  \n",
       "1 -87.698256  (41.992738481, -87.698256423)  \n",
       "2 -87.768174  (41.971605914, -87.768174187)  \n",
       "3        NaN                            NaN  \n",
       "4        NaN                            NaN  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084b200f",
   "metadata": {},
   "source": [
    "**.groupby()** is another powerful built-in function in Pandas. We can use it to group the entries of a DataFrame according to the values of the specific feature. Then, the following function The .groupby() method is applied to a DataFrame and groups it according to a feature. Then, we can apply some simple or more complicated functions on that grouped object. This is a very important tool for every data scientist working on tabular or structured data as it will help you to manipulate data easily and in a more effective way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fa7c035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.2 #percentage missing data required\n",
    "\n",
    "mask = np.random.choice([np.nan,1], size=len(df_data), p=[p,1-p])\n",
    "df_datanan = df_data.copy()\n",
    "df_datanan['Ward'] =  df_datanan['Ward'] * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d604d43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        22.0\n",
       "1         6.0\n",
       "2        50.0\n",
       "3        48.0\n",
       "4        40.0\n",
       "         ... \n",
       "36077    34.0\n",
       "36078    27.0\n",
       "36079     8.0\n",
       "36080     2.0\n",
       "36081    17.0\n",
       "Name: Ward, Length: 36082, dtype: float64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_trans = lambda x: x.fillna(x.mean())\n",
    "df_datanan_grouped = df_datanan.groupby('Primary Type')['Ward']\n",
    "df_datanan_grouped.transform(missing_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21649358",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "restaurant_grouped = restaurant.groupby('day')\n",
    "filter_trans = lambda x : x['total_bill'].mean() > 20\n",
    "restaurant_filtered = restaurant_grouped.filter(filter_trans)\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
