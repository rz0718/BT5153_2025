{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d37198f5",
      "metadata": {
        "id": "d37198f5"
      },
      "source": [
        "## How to use Pandas more efficiently"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b07589fe",
      "metadata": {
        "id": "b07589fe"
      },
      "source": [
        "The Pandas library is the tool that almost every data scientist will use every day. It is an awesome tool to explore and work with data.\n",
        "\n",
        "In this notebook, we would like to share a few good tricks such as using built-in functions and adopting vectorized operations that can speed up our pandas code and improve our productivity. The agenda would be:\n",
        "\n",
        "1. Selecting Rows and Columns using **.iloc[]** function is faster\n",
        "\n",
        "2. To iterate through all of rows of a dataframe, in terms of efficiency, vectorizing over pandas series > **.apply()** > **.iterrows()**\n",
        "\n",
        "3. Try to use more built-in functions such as **groupby()** functions. It could also speed up the process than our coding from scratch.\n",
        "\n",
        "In the following notebook, we will use the following dataset from Kaggle:\n",
        "\n",
        "\n",
        "[Crime in Chicago](https://www.kaggle.com/datasets/onlyrohit/crimes-in-chicago?resource=download)\n",
        "\n",
        "We took a random sample from it and the csv file is named **crimes_in_Chicago_subset.csv** which contains 36082 data points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b3b33ad1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3b33ad1",
        "outputId": "8ce2a2de-68f6-4a34-f392-c4d8d090ebe6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/BT5153_2025/codes/lab_lecture01/\n",
            "/content/gdrive/My Drive/BT5153_2025/codes/lab_lecture01\n"
          ]
        }
      ],
      "source": [
        "### if we are using google colab, we need to run this cell to specify the path for data loading\n",
        "import sys, os\n",
        "if 'google.colab' in sys.modules:\n",
        "    # mount google drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    # specify the path of the folder containing \"file_name\" by changing the lecture index:\n",
        "    lecture_index = '01'\n",
        "    path_to_file = '/content/gdrive/My Drive/BT5153_2025/codes/lab_lecture{}/'.format(lecture_index)\n",
        "    print(path_to_file)\n",
        "    # change current path to the folder containing \"file_name\"\n",
        "    os.chdir(path_to_file)\n",
        "    !pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d2b9d0eb",
      "metadata": {
        "id": "d2b9d0eb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df_data = pd.read_csv('../data/crimes_in_Chicago_subset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cac3b580",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cac3b580",
        "outputId": "7e38192c-c7b4-4b29-c6e9-6cf01d6f629f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(36082, 22)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45f00d04",
      "metadata": {
        "id": "45f00d04"
      },
      "source": [
        "### 1. Select rows and columns efficiently"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "092ff2e7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "092ff2e7",
        "outputId": "0e6700bc-9628-4c37-ceb2-b3d59a7133f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The slowest run took 5.21 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "971 µs ± 831 µs per loop (mean ± std. dev. of 5 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit -r5 -n10 df_data.loc[range(0,600)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "33dc540e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33dc540e",
        "outputId": "dd2b5524-3eee-4fdd-d1b9-7475df6c2921"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "195 µs ± 85.9 µs per loop (mean ± std. dev. of 5 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit -r5 -n10 df_data.iloc[range(0,600)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed4fcd9c",
      "metadata": {
        "id": "ed4fcd9c"
      },
      "source": [
        "We can see iloc[] perform much faster than loc[] in selecting rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "38c4e9b6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38c4e9b6",
        "outputId": "2d3d2d95-be53-4f0d-885a-416569bed7aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.81 ms ± 947 µs per loop (mean ± std. dev. of 5 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "sub_cols = [\"ID\", \"Case Number\", \"Date\", \"Block\"]\n",
        "%timeit -r5 -n10 df_data.loc[:,sub_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "18dbbf7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18dbbf7c",
        "outputId": "38afd06f-4271-44fc-f011-902ababf50b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.07 ms ± 353 µs per loop (mean ± std. dev. of 5 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "first3_cols = df_data.columns[:4]\n",
        "%timeit -r5 -n10 df_data.iloc[:,:4]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b15d793d",
      "metadata": {
        "id": "b15d793d"
      },
      "source": [
        "We can see also that using the column indexing using .iloc[] is still faster than loc[]. So it is better to use .iloc[] for efficiency. However, sometimes, it would be more convenient to use .loc[] to select certain columns by name directly"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8c77262",
      "metadata": {
        "id": "d8c77262"
      },
      "source": [
        "### 2. Iterate through all rows of Dataframe\n",
        "\n",
        "It is quite common to create a new column based on one or more current columns using Pandas. Think about feature engineering. We can see the different ways for this operation using Pandas. The performances would be compared.\n",
        "\n",
        "For example, we would like to create a new column which is the sum of square of **X Coordinate** and **Y Coordinate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b4cea744",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4cea744",
        "outputId": "e19f5755-076b-4b39-ff85-cb7ae1fc1ba9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25\n"
          ]
        }
      ],
      "source": [
        "sum_square = lambda x, y: (x+y) ** 2\n",
        "print(sum_square(2,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9ca89a21",
      "metadata": {
        "id": "9ca89a21"
      },
      "outputs": [],
      "source": [
        "test_data = df_data[['X Coordinate', 'Y Coordinate']].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "04fddd10",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04fddd10",
        "outputId": "587d7ea3-c106-4397-d062-28ca711f2e50",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "402 ms ± 5.84 ms per loop (mean ± std. dev. of 5 runs, 10 loops each)\n",
            "121 ms ± 3.35 ms per loop (mean ± std. dev. of 5 runs, 10 loops each)\n",
            "31.3 ms ± 127 µs per loop (mean ± std. dev. of 5 runs, 10 loops each)\n",
            "4.85 ms ± 68.1 µs per loop (mean ± std. dev. of 5 runs, 10 loops each)\n",
            "235 µs ± 26.3 µs per loop (mean ± std. dev. of 5 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit -r5 -n10 test_data.loc[:,'magic'] = [sum_square(value[0], value[1]) for _, value in test_data.iterrows()]\n",
        "%timeit -r5 -n10 test_data.loc[:,'magic'] = test_data.apply(lambda row: sum_square(row[0], row[1]), axis=1)\n",
        "%timeit -r5 -n10 test_data.loc[:,'magic']  = test_data.apply(lambda row: sum_square(row[0], row[1]), raw=True, axis=1)\n",
        "%timeit -r5 -n10 test_data.loc[:,'magic']  = np.vectorize(sum_square)(test_data.iloc[:,0], test_data.iloc[:,1])\n",
        "%timeit -r5 -n10 test_data.loc[:,'magic']  = np.power(test_data.iloc[:,0]+test_data.iloc[:,1], 2)\n",
        "#%timeit -r5 -n10 test_data.loc[:,'magic'] = [sum_square(value[0], value[1]) for _, value in test_data.iterrows()]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a82edf7e",
      "metadata": {
        "id": "a82edf7e"
      },
      "source": [
        "The best solution is able to achieve **1700** time speed-up compared to the slowest one  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "377ff592",
      "metadata": {
        "id": "377ff592"
      },
      "source": [
        "#### Key Take-away:\n",
        "\n",
        "1. You should never use iterrows(). If you need to loop through a dataframe, try **itertuples**\n",
        "2. **raw=True** in the **apply** function is able to  bypass the overhead associated with the Pandas series object. Therefore, it can speed up the apply process.\n",
        "3. Make the function \"vetorized\" can yield the highest speed up.\n",
        "\n",
        "In most of cases, if the operation can be represented as linear algebra operations on matrices and scalar values, it can be vectorized using Numpy methods.\n",
        "\n",
        "For some operations/functions, it might not be easily vectorized. I prefer parallel processing because it requires the least amount of rewrite of your existing code. You simply have to add a few lines wrapper code to make it work. The example below illustrates how you can do this. For example, we can try **[Dask](https://www.dask.org/)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "K7-T1Faaakdk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7-T1Faaakdk",
        "outputId": "4c806df4-da0f-480a-828a-e629cd1bc830"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: no matches found: dask[dataframe]\n"
          ]
        }
      ],
      "source": [
        "!pip install -q dask[dataframe]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "aa827b28",
      "metadata": {
        "id": "aa827b28"
      },
      "outputs": [],
      "source": [
        "import dask.dataframe as dd\n",
        "test_data = df_data[['X Coordinate', 'Y Coordinate']].copy()\n",
        "ddf = dd.from_pandas(test_data, npartitions=4)\n",
        "sum_square = lambda row: (row[0]+row[1]) ** 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "13851cac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13851cac",
        "outputId": "a84aa8e2-eb72-4dc2-ccee-af966d883543"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.15 ms ± 151 µs per loop (mean ± std. dev. of 5 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -r5 -n10\n",
        "dask_series = ddf.apply(sum_square, axis=1, meta=('magic','float'))\n",
        "ddf['magic'] = dask_series\n",
        "df_new = ddf.compute"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c189428b",
      "metadata": {
        "id": "c189428b"
      },
      "source": [
        "The parallelization is able to have a 2.8 times speed up compared to the apply function in the mode of the serial processing.\n",
        "\n",
        "But for parallel processing, there is a difference between CPU bound (heavy scientific computing and data is in memory) vs I/O bound (making API request over internet). For cpu bound, we should use multiprocess while the task is I/O bound, the multithreading one would be better choice.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "770d2359",
      "metadata": {
        "id": "770d2359"
      },
      "source": [
        "### 3. Try to use build-in functions in Pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "084b200f",
      "metadata": {
        "id": "084b200f"
      },
      "source": [
        "**.groupby()** is one powerful built-in function in Pandas. We can use it to group the entries of a DataFrame according to the values of the specific feature. Then, the following function The .groupby() method is applied to a DataFrame and groups it according to a feature. Then, we can apply some simple or more complicated functions on that grouped object. This is a very important tool for every data scientist working on tabular or structured data as it will help you to manipulate data easily and in a more effective way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "fa7c035d",
      "metadata": {
        "id": "fa7c035d"
      },
      "outputs": [],
      "source": [
        "p = 0.2 #percentage missing data required\n",
        "\n",
        "mask = np.random.choice([np.nan,1], size=len(df_data), p=[p,1-p])\n",
        "df_datanan = df_data.copy()\n",
        "df_datanan['Ward'] =  df_datanan['Ward'] * mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d604d43d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "d604d43d",
        "outputId": "a66a9ce1-70dd-4aba-f837-08d542331446"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        22.000000\n",
              "1         6.000000\n",
              "2        50.000000\n",
              "3        48.000000\n",
              "4        22.216384\n",
              "           ...    \n",
              "36077    34.000000\n",
              "36078    27.000000\n",
              "36079    24.984009\n",
              "36080     2.000000\n",
              "36081    21.925786\n",
              "Name: Ward, Length: 36082, dtype: float64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "missing_trans = lambda x: x.fillna(x.mean())\n",
        "df_datanan_grouped = df_datanan.groupby('Primary Type')['Ward']\n",
        "df_datanan_grouped.transform(missing_trans)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
