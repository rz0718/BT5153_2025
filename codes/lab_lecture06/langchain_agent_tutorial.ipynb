{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c3b5463",
   "metadata": {},
   "source": [
    "# LangChain Tool & Agent Tutorial\n",
    "This tutorial demonstrates how to:\n",
    "1. Create custom tools for LLMs\n",
    "2. Use tools with LLMs directly\n",
    "3. Build a tool-calling agent with AgentExecutor\n",
    "4. Build a ReAct agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74296c5",
   "metadata": {},
   "source": [
    "## 1. Setup: Loading the Language Model\n",
    "First, we'll load GPT-4 through the OpenAI API. We use ChatOpenAI because it's better at following instructions\n",
    "and using tools compared to base chat models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c37713e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LLM Models\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e56ca24",
   "metadata": {},
   "source": [
    "## 2. Creating Custom Tools\n",
    "Tools in LangChain are functions that LLMs can use to interact with external systems or perform computations.\n",
    "Each tool should:\n",
    "- Have clear documentation (docstring)\n",
    "- Have type hints for inputs and outputs\n",
    "- Perform a single, well-defined task\n",
    "Below we create two example tools:\n",
    "1. A simple multiplication tool\n",
    "2. A mock temperature lookup tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "665082a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "# The @tool decorator automatically converts our Python functions into LangChain tools\n",
    "# It uses the function's docstring and type hints to tell the LLM how to use the tool\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "@tool\n",
    "def gettempature(a: str) -> float:\n",
    "    \"\"\"Get the tempature of a city named a in celsius.\n",
    "\n",
    "    Args:\n",
    "        a: city name\n",
    "    \"\"\"\n",
    "    return 23.5\n",
    "\n",
    "\n",
    "# Create a list of available tools\n",
    "tools = [multiply, gettempature]\n",
    "\n",
    "# Bind the tools to our LLM\n",
    "# This creates a new LLM that knows about and can use these tools\n",
    "llm_with_tools = llm.bind_tools([multiply, gettempature])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63ed9e3",
   "metadata": {},
   "source": [
    "#### 2.1 Basic Tool Usage\n",
    "Let's first see how the LLM behaves when it doesn't need to use any tools.\n",
    "The LLM should recognize that a simple greeting doesn't require tool usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5fa1f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Hello! How can I assist you today?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 96, 'total_tokens': 107, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_4691090a87', 'finish_reason': 'stop', 'logprobs': None} id='run-9529ef0b-08b5-4db7-8830-347ef492ef6a-0' usage_metadata={'input_tokens': 96, 'output_tokens': 11, 'total_tokens': 107, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "result = llm_with_tools.invoke(\"Hello world!\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8881b040",
   "metadata": {},
   "source": [
    "#### 2.2 Tool Selection and Usage\n",
    "Now let's see how the LLM handles a question that could benefit from using a tool.\n",
    "The LLM should:\n",
    "1. Recognize that the multiplication tool is relevant\n",
    "2. Call the tool with appropriate parameters\n",
    "3. Use the tool's output to form its response\n",
    "4. Pass the execution result to LLM to form the final response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4ff535e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_4zP2wXRtPjEsd0Y5SB63pmgr', 'function': {'arguments': '{\"a\":3,\"b\":2}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 102, 'total_tokens': 120, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_50cad350e4', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-75e86024-ff06-48af-bef2-f95249502ae9-0' tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 2}, 'id': 'call_4zP2wXRtPjEsd0Y5SB63pmgr', 'type': 'tool_call'}] usage_metadata={'input_tokens': 102, 'output_tokens': 18, 'total_tokens': 120, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='6', name='multiply', tool_call_id='call_4zP2wXRtPjEsd0Y5SB63pmgr')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = llm_with_tools.invoke(\"What is 3 times by 2?\")\n",
    "print(result)\n",
    "# Use the generated JSON schema to execute the tool\n",
    "multiply.invoke(result.tool_calls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "667f86df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_B41os198KLSp2MN6EiucPihw', 'function': {'arguments': '{\"a\":\"Kent Ridge\"}', 'name': 'gettempature'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 101, 'total_tokens': 118, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_50cad350e4', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-ab4e135f-bdbf-4d8b-a1c7-acffe6a8e10d-0' tool_calls=[{'name': 'gettempature', 'args': {'a': 'Kent Ridge'}, 'id': 'call_B41os198KLSp2MN6EiucPihw', 'type': 'tool_call'}] usage_metadata={'input_tokens': 101, 'output_tokens': 17, 'total_tokens': 118, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='23.5', name='gettempature', tool_call_id='call_B41os198KLSp2MN6EiucPihw')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = llm_with_tools.invoke(\"What is the temperature at Kent Ridge?\")\n",
    "print(result)\n",
    "gettempature.invoke(result.tool_calls[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff090774",
   "metadata": {},
   "source": [
    "#### 2.3 Pass the execution result to LLM\n",
    "\n",
    "Here we'll see how to handle tool calls manually without using LangChain's high-level abstractions.\n",
    "This helps understand what's happening under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f507b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Example query that should trigger tool usage\n",
    "query = \"What is the temperature at Kent Ridge?\"\n",
    "\n",
    "# Create a conversation with system and user messages\n",
    "messages = [SystemMessage(\"You are a helpful assistant\"), HumanMessage(query)]\n",
    "\n",
    "# Get the AI's response, which may include tool calls\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)\n",
    "\n",
    "# Process any tool calls in the response\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    # Map tool names to actual tool functions\n",
    "    selected_tool = {\"multiply\": multiply, \"gettempature\": gettempature}[\n",
    "        tool_call[\"name\"].lower()\n",
    "    ]\n",
    "    # Execute the tool and get its response\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    # Add the tool's response to the conversation\n",
    "    messages.append(tool_msg)\n",
    "\n",
    "# Get the final response incorporating tool results\n",
    "final_ai_msg = llm_with_tools.invoke(messages)\n",
    "messages.append(final_ai_msg)\n",
    "\n",
    "# Print the entire conversation\n",
    "print(\"Full conversation with tool usage:\")\n",
    "for message in messages:\n",
    "    print(message)\n",
    "    print(\"---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af54ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70921f1",
   "metadata": {},
   "source": [
    "## 3. Wrap up: Build tool-calling agent with AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "484610c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant. Respond only in Korean.\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "343bf58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the tempature of Kent Ridge?',\n",
       " 'output': '켄트 리지의 온도는 섭씨 23.5도입니다.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"What is the tempature of Kent Ridge?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fd9c97",
   "metadata": {},
   "source": [
    "## 4. Build a ReAct Agent\n",
    "\n",
    "Here we'll use the ReAct (Reasoning + Acting) agent, which:\n",
    "1. Thinks about what to do (Reasoning)\n",
    "2. Takes actions using tools (Acting)\n",
    "3. Observes results\n",
    "4. Repeats until the task is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5032f41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rz/Documents/projects_code/.venv/lib/python3.12/site-packages/langsmith/client.py:256: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Set up a search tool for the agent to use\n",
    "tools = [TavilySearchResults(max_results=1)]\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "# Construct the ReAct agent\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "# Create an agent executor by passing in the agent and tools\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec95a3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the agent on a complex query that requires:\n",
    "# 1. Understanding the question\n",
    "# 2. Searching for relevant information\n",
    "# 3. Extracting the specific detail requested\n",
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"What is the headquarters of the company where the lecturer of BT5153 works? BT5153 is a module offered by NUS, MBSA.?\"\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
